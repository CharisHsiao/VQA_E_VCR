{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from '/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/version.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/vcr1images\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/')\n",
    "from dataloaders.vcr import VCR, VCRLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training script. Should be pretty adaptable to whatever.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.training.learning_rate_schedulers import LearningRateScheduler\n",
    "from allennlp.training.optimizers import Optimizer\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.modules import BatchNorm2d\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataloaders.vcr import VCR, VCRLoader\n",
    "from utils.pytorch_misc import time_batch, save_checkpoint, clip_grad_norm, \\\n",
    "    restore_checkpoint, print_para, restore_best_checkpoint\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', level=logging.DEBUG)\n",
    "\n",
    "# This is needed to make the imports work\n",
    "from allennlp.models import Model\n",
    "import models\n",
    "# import sys\n",
    "# sys.path.append(\"/home/lab/A305/yifan/vqa/vqa-exp/r2c/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-no_tqdm'], dest='no_tqdm', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################\n",
    "#################################\n",
    "######## Data loading stuff\n",
    "#################################\n",
    "#################################\n",
    "\n",
    "parser = argparse.ArgumentParser(description='train')\n",
    "parser.add_argument(\n",
    "    '-params',\n",
    "    dest='params',\n",
    "    help='Params location',\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-rationale',\n",
    "    action=\"store_true\",\n",
    "    help='use rationale',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-folder',\n",
    "    dest='folder',\n",
    "    help='folder location',\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-no_tqdm',\n",
    "    dest='no_tqdm',\n",
    "    action='store_true',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "bert_da\n",
      "<class 'str'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KeysView(<allennlp.common.params.Params object at 0x7fe0ce46be48>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "args.params = \"multiatt_scene/default.json\"\n",
    "args.folder = \"saves/multiatt_scene/flagship_answer\"\n",
    "args.no_tqdm = True\n",
    "\n",
    "params = Params.from_file(args.params)\n",
    "print(args.no_tqdm)\n",
    "# print(params.values)\n",
    "# param=params['model']\n",
    "# print(param)\n",
    "# print(param['type'])\n",
    "embs_to_load=params['dataset_reader'].get('embs', 'bert_da')\n",
    "print(embs_to_load)\n",
    "print(type(embs_to_load))\n",
    "# type(params['dataset_reader'])\n",
    "params['dataset_reader'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_train.h5\n",
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_val.h5\n",
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_test.h5\n"
     ]
    }
   ],
   "source": [
    "train, val, test = VCR.splits(mode='rationale' if args.rationale else 'answer',\n",
    "                              embs_to_load=params['dataset_reader'].get('embs', 'bert_da'),\n",
    "                              only_use_relevant_dets=params['dataset_reader'].get('only_use_relevant_dets', True))\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "NUM_CPUS = multiprocessing.cpu_count()\n",
    "if NUM_GPUS == 0:\n",
    "    raise ValueError(\"you need gpus!\")\n",
    "\n",
    "def _to_gpu(td):\n",
    "    if NUM_GPUS > 1:\n",
    "        return td\n",
    "    for k in td:\n",
    "        if k != 'metadata':\n",
    "            td[k] = {k2: v.cuda(non_blocking=True) for k2, v in td[k].items()} if isinstance(td[k], dict) else td[k].cuda(\n",
    "                non_blocking=True)\n",
    "    return td\n",
    "num_workers = (4 * NUM_GPUS if NUM_CPUS >= 32 else 2*NUM_GPUS)-1\n",
    "#print(f\"Using {num_workers} workers out of {NUM_CPUS} possible\", flush=True)\n",
    "# print(f\"Using {num_workers} workers out of {NUM_CPUS} possible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MultiAttentionQA_Scene for answer\n"
     ]
    }
   ],
   "source": [
    "loader_params = {'batch_size': 96 // NUM_GPUS, 'num_gpus':NUM_GPUS, 'num_workers':num_workers}\n",
    "train_loader = VCRLoader.from_dataset(train, **loader_params)\n",
    "val_loader = VCRLoader.from_dataset(val, **loader_params)\n",
    "test_loader = VCRLoader.from_dataset(test, **loader_params)\n",
    "\n",
    "ARGS_RESET_EVERY = 100\n",
    "#print(\"Loading {} for {}\".format(params['model'].get('type', 'WTF?'), 'rationales' if args.rationale else 'answer'), flush=True)\n",
    "print(\"Loading {} for {}\".format(params['model'].get('type', 'WTF?'), 'rationales' if args.rationale else 'answer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {'hidden_dim_maxpool': 1024, 'initializer': [['.*final_mlp.*weight', {'type': 'xavier_uniform'}], ['.*final_mlp.*bias', {'type': 'zero'}], ['.*weight_ih.*', {'type': 'xavier_uniform'}], ['.*weight_hh.*', {'type': 'orthogonal'}], ['.*bias_ih.*', {'type': 'zero'}], ['.*bias_hh.*', {'type': 'lstm_hidden_bias'}]], 'input_dropout': 0.3, 'pool_answer': True, 'pool_question': True, 'reasoning_encoder': {'bidirectional': True, 'hidden_size': 256, 'input_size': 1536, 'num_layers': 2, 'type': 'lstm'}, 'span_encoder': {'bidirectional': True, 'hidden_size': 256, 'input_size': 768, 'num_layers': 1, 'type': 'lstm'}, 'type': 'MultiAttentionQA_Scene'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe038946048>}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.type = MultiAttentionQA_Scene\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'models.multiatt_scene.model.AttentionQA'> from params {'hidden_dim_maxpool': 1024, 'initializer': [['.*final_mlp.*weight', {'type': 'xavier_uniform'}], ['.*final_mlp.*bias', {'type': 'zero'}], ['.*weight_ih.*', {'type': 'xavier_uniform'}], ['.*weight_hh.*', {'type': 'orthogonal'}], ['.*bias_ih.*', {'type': 'zero'}], ['.*bias_hh.*', {'type': 'lstm_hidden_bias'}]], 'input_dropout': 0.3, 'pool_answer': True, 'pool_question': True, 'reasoning_encoder': {'bidirectional': True, 'hidden_size': 256, 'input_size': 1536, 'num_layers': 2, 'type': 'lstm'}, 'span_encoder': {'bidirectional': True, 'hidden_size': 256, 'input_size': 768, 'num_layers': 1, 'type': 'lstm'}} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe038946048>}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'hidden_size': 256, 'input_size': 768, 'num_layers': 1, 'type': 'lstm'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe038946048>}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.type = lstm\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.batch_first = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.stateful = False\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.bidirectional = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.hidden_size = 256\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.input_size = 768\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.num_layers = 1\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.span_encoder.batch_first = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.modules.seq2seq_encoders.seq2seq_encoder.Seq2SeqEncoder'> from params {'bidirectional': True, 'hidden_size': 256, 'input_size': 1536, 'num_layers': 2, 'type': 'lstm'} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7fe038946048>}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.type = lstm\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.batch_first = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.stateful = False\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.bidirectional = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.hidden_size = 256\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.input_size = 1536\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.num_layers = 2\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_encoder.batch_first = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.input_dropout = 0.3\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.hidden_dim_maxpool = 1024\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.class_embs = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_use_obj = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_use_answer = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.reasoning_use_question = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.pool_reasoning = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.pool_answer = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.pool_question = True\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.qa_visual = False\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer = [['.*final_mlp.*weight', {'type': 'xavier_uniform'}], ['.*final_mlp.*bias', {'type': 'zero'}], ['.*weight_ih.*', {'type': 'xavier_uniform'}], ['.*weight_hh.*', {'type': 'orthogonal'}], ['.*bias_ih.*', {'type': 'zero'}], ['.*bias_hh.*', {'type': 'lstm_hidden_bias'}]]\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'xavier_uniform'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = xavier_uniform\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'zero'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = zero\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'xavier_uniform'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = xavier_uniform\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'orthogonal'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = orthogonal\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'zero'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = zero\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.nn.initializers.Initializer'> from params {'type': 'lstm_hidden_bias'} and extras {}\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   model.initializer.list.list.type = lstm_hidden_bias\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:06 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~init_0~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing parameters\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.weight_ih_l0 using .*weight_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.weight_hh_l0 using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.bias_ih_l0 using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.bias_hh_l0 using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.weight_ih_l0_reverse using .*weight_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.weight_hh_l0_reverse using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.bias_ih_l0_reverse using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing span_encoder._module._module.bias_hh_l0_reverse using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_ih_l0 using .*weight_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_hh_l0 using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_ih_l0 using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_hh_l0 using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_ih_l0_reverse using .*weight_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_hh_l0_reverse using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_ih_l0_reverse using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_hh_l0_reverse using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_ih_l1 using .*weight_ih.* intitializer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~init_0.1~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~init_0.2~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "init_1\n",
      "init_2\n",
      "init_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_hh_l1 using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_ih_l1 using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_hh_l1 using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_ih_l1_reverse using .*weight_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.weight_hh_l1_reverse using .*weight_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_ih_l1_reverse using .*bias_ih.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing reasoning_encoder._module._module.bias_hh_l1_reverse using .*bias_hh.* intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing final_mlp.1.weight using .*final_mlp.*weight intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing final_mlp.1.bias using .*final_mlp.*bias intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing final_mlp.4.weight using .*final_mlp.*weight intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Initializing final_mlp.4.bias using .*final_mlp.*bias intitializer\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -   Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.downsample.0.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.downsample.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.0.downsample.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.1.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.after_roi_align.0.2.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.0.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.downsample.0.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.downsample.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.0.downsample.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.1.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.4.2.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn2.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.downsample.0.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.downsample.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.0.downsample.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.1.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.2.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.5.3.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.downsample.0.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.downsample.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.0.downsample.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.1.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.2.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.3.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.4.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn2.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn2.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn3.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.bn3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.conv1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.conv2.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.backbone.6.5.conv3.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.mask_upsample.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.mask_upsample.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.obj_downsample.1.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.obj_downsample.1.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.object_embed.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.regularizing_predictor.bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      detector.regularizing_predictor.weight\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      obj_attention._bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      obj_attention._weight_matrix\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      span_attention._bias\n",
      "03/27/2019 01:24:07 - INFO - allennlp.nn.initializers -      span_attention._weight_matrix\n"
     ]
    }
   ],
   "source": [
    "model = Model.from_params(vocab=train.vocab, params=params['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.optimizer.type = adam\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.optimizer.parameter_groups = None\n",
      "03/27/2019 01:24:11 - INFO - allennlp.training.optimizers -   Number of trainable parameters: 25707540\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.optimizer.lr = 0.0002\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.optimizer.weight_decay = 0.0001\n"
     ]
    }
   ],
   "source": [
    "for submodule in model.detector.backbone.modules():\n",
    "    if isinstance(submodule, BatchNorm2d):\n",
    "        submodule.track_running_stats = False\n",
    "    for p in submodule.parameters():\n",
    "        p.requires_grad = False\n",
    "model = DataParallel(model).cuda() if NUM_GPUS > 1 else model.cuda()\n",
    "\n",
    "optimizer = Optimizer.from_params([x for x in model.named_parameters() if x[1].requires_grad],\n",
    "                                  params['trainer']['optimizer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.type = reduce_on_plateau\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   CURRENTLY DEFINED PARAMETERS: \n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.cooldown = 2\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.factor = 0.5\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.mode = max\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.patience = 1\n",
      "03/27/2019 01:24:11 - INFO - allennlp.common.params -   trainer.learning_rate_scheduler.verbose = True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found folder! restoring\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler_params = params['trainer'].pop(\"learning_rate_scheduler\", None)\n",
    "scheduler = LearningRateScheduler.from_params(optimizer, lr_scheduler_params) if lr_scheduler_params else None\n",
    "if os.path.exists(args.folder):\n",
    "    #print(\"Found folder! restoring\", flush=True)\n",
    "    print(\"Found folder! restoring\")\n",
    "    start_epoch, val_metric_per_epoch = restore_checkpoint(model, optimizer, serialization_dir=args.folder,\n",
    "                                                           learning_rate_scheduler=scheduler)\n",
    "else:\n",
    "    print(\"Making directories\")\n",
    "    os.makedirs(args.folder, exist_ok=True)\n",
    "    start_epoch, val_metric_per_epoch = 0, []\n",
    "    shutil.copy2(args.params, args.folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 34.3M total parameters. 25.7M training \n",
      " ----- \n",
      "                                                               shape     size  requires_grad\n",
      "name                                                                                       \n",
      "detector.after_roi_align.0.0.conv2.weight             [512,512,3,3]  2359296           True\n",
      "detector.after_roi_align.0.1.conv2.weight             [512,512,3,3]  2359296           True\n",
      "detector.after_roi_align.0.2.conv2.weight             [512,512,3,3]  2359296           True\n",
      "detector.after_roi_align.0.0.downsample.0.weight    [2048,1024,1,1]  2097152           True\n",
      "reasoning_encoder._module._module.weight_ih_l0          [1024,1536]  1572864           True\n",
      "reasoning_encoder._module._module.weight_ih_l0_...      [1024,1536]  1572864           True\n",
      "final_mlp.1.weight                                      [1024,1536]  1572864           True\n",
      "detector.obj_downsample.1.weight                         [512,2176]  1114112           True\n",
      "detector.after_roi_align.0.0.conv3.weight            [2048,512,1,1]  1048576           True\n",
      "detector.after_roi_align.0.1.conv1.weight            [512,2048,1,1]  1048576           True\n",
      "detector.after_roi_align.0.1.conv3.weight            [2048,512,1,1]  1048576           True\n",
      "detector.after_roi_align.0.2.conv1.weight            [512,2048,1,1]  1048576           True\n",
      "detector.after_roi_align.0.2.conv3.weight            [2048,512,1,1]  1048576           True\n",
      "span_encoder._module._module.weight_ih_l0                [1024,768]   786432           True\n",
      "span_encoder._module._module.weight_ih_l0_reverse        [1024,768]   786432           True\n",
      "detector.backbone.6.0.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.1.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.2.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.3.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.4.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.5.conv2.weight                    [256,256,3,3]   589824          False\n",
      "detector.backbone.6.0.downsample.0.weight            [1024,512,1,1]   524288          False\n",
      "detector.after_roi_align.0.0.conv1.weight            [512,1024,1,1]   524288           True\n",
      "reasoning_encoder._module._module.weight_ih_l1           [1024,512]   524288           True\n",
      "reasoning_encoder._module._module.weight_ih_l1_...       [1024,512]   524288           True\n",
      "detector.backbone.6.0.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "detector.backbone.6.1.conv1.weight                   [256,1024,1,1]   262144          False\n",
      "detector.backbone.6.1.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "detector.backbone.6.2.conv1.weight                   [256,1024,1,1]   262144          False\n",
      "detector.backbone.6.2.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "detector.backbone.6.3.conv1.weight                   [256,1024,1,1]   262144          False\n",
      "detector.backbone.6.3.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "detector.backbone.6.4.conv1.weight                   [256,1024,1,1]   262144          False\n",
      "detector.backbone.6.4.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "detector.backbone.6.5.conv1.weight                   [256,1024,1,1]   262144          False\n",
      "detector.backbone.6.5.conv3.weight                   [1024,256,1,1]   262144          False\n",
      "span_encoder._module._module.weight_hh_l0                [1024,256]   262144           True\n",
      "span_encoder._module._module.weight_hh_l0_reverse        [1024,256]   262144           True\n",
      "reasoning_encoder._module._module.weight_hh_l0           [1024,256]   262144           True\n",
      "reasoning_encoder._module._module.weight_hh_l0_...       [1024,256]   262144           True\n",
      "reasoning_encoder._module._module.weight_hh_l1           [1024,256]   262144           True\n",
      "reasoning_encoder._module._module.weight_hh_l1_...       [1024,256]   262144           True\n",
      "span_attention._weight_matrix                             [512,512]   262144           True\n",
      "obj_attention._weight_matrix                              [512,512]   262144           True\n",
      "detector.regularizing_predictor.weight                    [81,2048]   165888           True\n",
      "detector.backbone.5.0.conv2.weight                    [128,128,3,3]   147456          False\n",
      "detector.backbone.5.1.conv2.weight                    [128,128,3,3]   147456          False\n",
      "detector.backbone.5.2.conv2.weight                    [128,128,3,3]   147456          False\n",
      "detector.backbone.5.3.conv2.weight                    [128,128,3,3]   147456          False\n",
      "detector.backbone.5.0.downsample.0.weight             [512,256,1,1]   131072          False\n",
      "detector.backbone.6.0.conv1.weight                    [256,512,1,1]   131072          False\n",
      "detector.backbone.5.0.conv3.weight                    [512,128,1,1]    65536          False\n",
      "detector.backbone.5.1.conv1.weight                    [128,512,1,1]    65536          False\n",
      "detector.backbone.5.1.conv3.weight                    [512,128,1,1]    65536          False\n",
      "detector.backbone.5.2.conv1.weight                    [128,512,1,1]    65536          False\n",
      "detector.backbone.5.2.conv3.weight                    [512,128,1,1]    65536          False\n",
      "detector.backbone.5.3.conv1.weight                    [128,512,1,1]    65536          False\n",
      "detector.backbone.5.3.conv3.weight                    [512,128,1,1]    65536          False\n",
      "detector.backbone.4.0.conv2.weight                      [64,64,3,3]    36864          False\n",
      "detector.backbone.4.1.conv2.weight                      [64,64,3,3]    36864          False\n",
      "detector.backbone.4.2.conv2.weight                      [64,64,3,3]    36864          False\n",
      "detector.backbone.5.0.conv1.weight                    [128,256,1,1]    32768          False\n",
      "detector.backbone.4.0.conv3.weight                     [256,64,1,1]    16384          False\n",
      "detector.backbone.4.0.downsample.0.weight              [256,64,1,1]    16384          False\n",
      "detector.backbone.4.1.conv1.weight                     [64,256,1,1]    16384          False\n",
      "detector.backbone.4.1.conv3.weight                     [256,64,1,1]    16384          False\n",
      "detector.backbone.4.2.conv1.weight                     [64,256,1,1]    16384          False\n",
      "detector.backbone.4.2.conv3.weight                     [256,64,1,1]    16384          False\n",
      "detector.object_embed.weight                               [81,128]    10368           True\n",
      "detector.backbone.0.weight                               [64,3,7,7]     9408          False\n",
      "detector.backbone.4.0.conv1.weight                      [64,64,1,1]     4096          False\n",
      "detector.after_roi_align.0.0.bn3.weight                      [2048]     2048           True\n",
      "detector.after_roi_align.0.0.bn3.bias                        [2048]     2048           True\n",
      "detector.after_roi_align.0.0.downsample.1.weight             [2048]     2048           True\n",
      "detector.after_roi_align.0.0.downsample.1.bias               [2048]     2048           True\n",
      "detector.after_roi_align.0.1.bn3.weight                      [2048]     2048           True\n",
      "detector.after_roi_align.0.1.bn3.bias                        [2048]     2048           True\n",
      "detector.after_roi_align.0.2.bn3.weight                      [2048]     2048           True\n",
      "detector.after_roi_align.0.2.bn3.bias                        [2048]     2048           True\n",
      "detector.backbone.6.0.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.0.bn3.bias                               [1024]     1024          False\n",
      "detector.backbone.6.0.downsample.1.weight                    [1024]     1024          False\n",
      "detector.backbone.6.0.downsample.1.bias                      [1024]     1024          False\n",
      "detector.backbone.6.1.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.1.bn3.bias                               [1024]     1024          False\n",
      "detector.backbone.6.2.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.2.bn3.bias                               [1024]     1024          False\n",
      "detector.backbone.6.3.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.3.bn3.bias                               [1024]     1024          False\n",
      "detector.backbone.6.4.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.4.bn3.bias                               [1024]     1024          False\n",
      "detector.backbone.6.5.bn3.weight                             [1024]     1024          False\n",
      "detector.backbone.6.5.bn3.bias                               [1024]     1024          False\n",
      "span_encoder._module._module.bias_ih_l0                      [1024]     1024           True\n",
      "span_encoder._module._module.bias_hh_l0                      [1024]     1024           True\n",
      "span_encoder._module._module.bias_ih_l0_reverse              [1024]     1024           True\n",
      "span_encoder._module._module.bias_hh_l0_reverse              [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_ih_l0                 [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_hh_l0                 [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_ih_l0_re...           [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_hh_l0_re...           [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_ih_l1                 [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_hh_l1                 [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_ih_l1_re...           [1024]     1024           True\n",
      "reasoning_encoder._module._module.bias_hh_l1_re...           [1024]     1024           True\n",
      "final_mlp.1.bias                                             [1024]     1024           True\n",
      "final_mlp.4.weight                                         [1,1024]     1024           True\n",
      "detector.backbone.5.0.bn3.weight                              [512]      512          False\n",
      "detector.backbone.5.0.bn3.bias                                [512]      512          False\n",
      "detector.backbone.5.0.downsample.1.weight                     [512]      512          False\n",
      "detector.backbone.5.0.downsample.1.bias                       [512]      512          False\n",
      "detector.backbone.5.1.bn3.weight                              [512]      512          False\n",
      "detector.backbone.5.1.bn3.bias                                [512]      512          False\n",
      "detector.backbone.5.2.bn3.weight                              [512]      512          False\n",
      "detector.backbone.5.2.bn3.bias                                [512]      512          False\n",
      "detector.backbone.5.3.bn3.weight                              [512]      512          False\n",
      "detector.backbone.5.3.bn3.bias                                [512]      512          False\n",
      "detector.after_roi_align.0.0.bn1.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.0.bn1.bias                         [512]      512           True\n",
      "detector.after_roi_align.0.0.bn2.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.0.bn2.bias                         [512]      512           True\n",
      "detector.after_roi_align.0.1.bn1.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.1.bn1.bias                         [512]      512           True\n",
      "detector.after_roi_align.0.1.bn2.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.1.bn2.bias                         [512]      512           True\n",
      "detector.after_roi_align.0.2.bn1.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.2.bn1.bias                         [512]      512           True\n",
      "detector.after_roi_align.0.2.bn2.weight                       [512]      512           True\n",
      "detector.after_roi_align.0.2.bn2.bias                         [512]      512           True\n",
      "detector.obj_downsample.1.bias                                [512]      512           True\n",
      "detector.mask_upsample.weight                            [32,1,3,3]      288           True\n",
      "detector.backbone.4.0.bn3.weight                              [256]      256          False\n",
      "detector.backbone.4.0.bn3.bias                                [256]      256          False\n",
      "detector.backbone.4.0.downsample.1.weight                     [256]      256          False\n",
      "detector.backbone.4.0.downsample.1.bias                       [256]      256          False\n",
      "detector.backbone.4.1.bn3.weight                              [256]      256          False\n",
      "detector.backbone.4.1.bn3.bias                                [256]      256          False\n",
      "detector.backbone.4.2.bn3.weight                              [256]      256          False\n",
      "detector.backbone.4.2.bn3.bias                                [256]      256          False\n",
      "detector.backbone.6.0.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.0.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.0.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.0.bn2.bias                                [256]      256          False\n",
      "detector.backbone.6.1.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.1.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.1.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.1.bn2.bias                                [256]      256          False\n",
      "detector.backbone.6.2.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.2.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.2.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.2.bn2.bias                                [256]      256          False\n",
      "detector.backbone.6.3.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.3.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.3.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.3.bn2.bias                                [256]      256          False\n",
      "detector.backbone.6.4.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.4.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.4.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.4.bn2.bias                                [256]      256          False\n",
      "detector.backbone.6.5.bn1.weight                              [256]      256          False\n",
      "detector.backbone.6.5.bn1.bias                                [256]      256          False\n",
      "detector.backbone.6.5.bn2.weight                              [256]      256          False\n",
      "detector.backbone.6.5.bn2.bias                                [256]      256          False\n",
      "detector.backbone.5.0.bn1.weight                              [128]      128          False\n",
      "detector.backbone.5.0.bn1.bias                                [128]      128          False\n",
      "detector.backbone.5.0.bn2.weight                              [128]      128          False\n",
      "detector.backbone.5.0.bn2.bias                                [128]      128          False\n",
      "detector.backbone.5.1.bn1.weight                              [128]      128          False\n",
      "detector.backbone.5.1.bn1.bias                                [128]      128          False\n",
      "detector.backbone.5.1.bn2.weight                              [128]      128          False\n",
      "detector.backbone.5.1.bn2.bias                                [128]      128          False\n",
      "detector.backbone.5.2.bn1.weight                              [128]      128          False\n",
      "detector.backbone.5.2.bn1.bias                                [128]      128          False\n",
      "detector.backbone.5.2.bn2.weight                              [128]      128          False\n",
      "detector.backbone.5.2.bn2.bias                                [128]      128          False\n",
      "detector.backbone.5.3.bn1.weight                              [128]      128          False\n",
      "detector.backbone.5.3.bn1.bias                                [128]      128          False\n",
      "detector.backbone.5.3.bn2.weight                              [128]      128          False\n",
      "detector.backbone.5.3.bn2.bias                                [128]      128          False\n",
      "detector.regularizing_predictor.bias                           [81]       81           True\n",
      "detector.backbone.1.weight                                     [64]       64          False\n",
      "detector.backbone.1.bias                                       [64]       64          False\n",
      "detector.backbone.4.0.bn1.weight                               [64]       64          False\n",
      "detector.backbone.4.0.bn1.bias                                 [64]       64          False\n",
      "detector.backbone.4.0.bn2.weight                               [64]       64          False\n",
      "detector.backbone.4.0.bn2.bias                                 [64]       64          False\n",
      "detector.backbone.4.1.bn1.weight                               [64]       64          False\n",
      "detector.backbone.4.1.bn1.bias                                 [64]       64          False\n",
      "detector.backbone.4.1.bn2.weight                               [64]       64          False\n",
      "detector.backbone.4.1.bn2.bias                                 [64]       64          False\n",
      "detector.backbone.4.2.bn1.weight                               [64]       64          False\n",
      "detector.backbone.4.2.bn1.bias                                 [64]       64          False\n",
      "detector.backbone.4.2.bn2.weight                               [64]       64          False\n",
      "detector.backbone.4.2.bn2.bias                                 [64]       64          False\n",
      "detector.mask_upsample.bias                                    [32]       32           True\n",
      "span_attention._bias                                            [1]        1           True\n",
      "obj_attention._bias                                             [1]        1           True\n",
      "final_mlp.4.bias                                                [1]        1           True \n",
      " ----\n"
     ]
    }
   ],
   "source": [
    "param_shapes = print_para(model)\n",
    "num_batches = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n",
      "2222\n",
      "3333\n",
      "4444\n",
      "<class 'torch.Tensor'>\n",
      "<class 'dict'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "#######################images##################\n",
      "torch.Size([96, 3, 384, 768])\n",
      "#######################question##################\n",
      "1\n",
      "bert torch.Size([96, 4, 18, 768])\n",
      "#######################question_tags##################\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([96, 4, 18])\n",
      "#######################question_mask##################\n",
      "torch.Size([96, 4, 18])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "11111Stop by the user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-30153317dddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'4444'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'5555'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cnn_regularization_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/A305/yifan/vqa/vqa-exp/VQA_E_VCR/models/multiatt_scene/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, objects, segms, boxes, box_mask, question, question_tags, question_mask, answers, answer_tags, answer_mask, metadata, label)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#######################question_mask##################'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'11111Stop by the user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 11111Stop by the user"
     ]
    }
   ],
   "source": [
    "for epoch_num in range(start_epoch, params['trainer']['num_epochs'] + start_epoch):\n",
    "    train_results = []\n",
    "    norms = []\n",
    "    model.train()\n",
    "    print('1111')\n",
    "    for b, (time_per_batch, batch) in enumerate(time_batch(train_loader if args.no_tqdm else tqdm(train_loader), reset_every=ARGS_RESET_EVERY)):\n",
    "        print('2222')\n",
    "        batch = _to_gpu(batch)\n",
    "        print('3333')\n",
    "        optimizer.zero_grad()\n",
    "        print('4444')\n",
    "        output_dict = model(**batch)\n",
    "        print('5555')\n",
    "        loss = output_dict['loss'].mean() + output_dict['cnn_regularization_loss'].mean()\n",
    "        print('6666')\n",
    "        loss.backward()\n",
    "        print('7777')\n",
    "        num_batches += 1\n",
    "        if scheduler:\n",
    "            scheduler.step_batch(num_batches)\n",
    "        print('8888')\n",
    "        norms.append(\n",
    "            clip_grad_norm(model.named_parameters(), max_norm=params['trainer']['grad_norm'], clip=True, verbose=False)\n",
    "        )\n",
    "        print('9999')\n",
    "        optimizer.step()\n",
    "        print('0000')\n",
    "        exit()\n",
    "    exit()\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/resnet50_places365.pth.tar\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from functools import partial\n",
    "import pickle\n",
    "# from torch.utils.serialization import load_lua\n",
    "\n",
    "\n",
    "# th architecture to use\n",
    "arch = 'resnet50'\n",
    "# arch = 'resnet152'\n",
    "\n",
    "# load the pre-trained weights\n",
    "\n",
    "model_file = '%s_places365.pth.tar' % arch\n",
    "# model_file = '%s_places365.t7' % arch\n",
    "\n",
    "\n",
    "print(os.access(model_file, os.W_OK))\n",
    "\n",
    "\n",
    "# pickle.load = partial(pickle.load, encoding=\"latin1\")\n",
    "# pickle.Unpickler = partial(pickle.Unpickler, encoding=\"latin1\")\n",
    "# model = torch.load(model_file, map_location=lambda storage, loc: storage, pickle_module=pickle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.access(model_file, os.W_OK):\n",
    "    print('Downloading resnet50_places365.pth.tar')\n",
    "    weight_url = 'http://places2.csail.mit.edu/models_places365/' + model_file\n",
    "    os.system('wget ' + weight_url)\n",
    "    print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.__dict__[arch](num_classes=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=2048, out_features=365, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(model_file, map_location=lambda storage, loc: storage)\n",
    "state_dict = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image transformer\n",
    "from torchvision import transforms as trn\n",
    "centre_crop = trn.Compose([\n",
    "        trn.Resize((256,256)),\n",
    "        trn.CenterCrop(224),\n",
    "        trn.ToTensor(),\n",
    "        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the class label\n",
    "file_name = 'categories_places365.txt'\n",
    "if not os.access(file_name, os.W_OK):\n",
    "    synset_url = 'https://raw.githubusercontent.com/csailvision/places365/master/categories_places365.txt'\n",
    "    os.system('wget ' + synset_url)\n",
    "classes = list()\n",
    "with open(file_name) as class_file:\n",
    "    for line in class_file:\n",
    "        classes.append(line.strip().split(' ')[0][3:])\n",
    "classes = tuple(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the test image\n",
    "img_name = '12.jpg'\n",
    "if not os.access(img_name, os.W_OK):\n",
    "    img_url = 'http://places.csail.mit.edu/demo/' + img_name\n",
    "    os.system('wget ' + img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 3, 224, 224])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(img_name)\n",
    "print(type(img))\n",
    "temp = centre_crop(img).unsqueeze(0)\n",
    "print(type(temp))\n",
    "print(temp.size())\n",
    "input_img = V(temp)\n",
    "print(type(input_img))\n",
    "print(input_img.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet50 prediction on 12.jpg\n",
      "0.685 -> patio\n",
      "0.240 -> restaurant_patio\n",
      "0.019 -> beer_garden\n",
      "0.010 -> courtyard\n",
      "0.010 -> porch\n"
     ]
    }
   ],
   "source": [
    "# forward pass\n",
    "logit = model.forward(input_img)\n",
    "h_x = F.softmax(logit, 1).data.squeeze()\n",
    "probs, idx = h_x.sort(0, True)\n",
    "\n",
    "print('{} prediction on {}'.format(arch,img_name))\n",
    "# output the prediction\n",
    "for i in range(0, 5):\n",
    "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "# from torchvision.models import resnet\n",
    "\n",
    "# from utils.pytorch_misc import Flattener\n",
    "# from torchvision.layers import ROIAlign\n",
    "# import torch.utils.model_zoo as model_zoo\n",
    "USE_IMAGENET_PRETRAINED = True\n",
    "# from utils.pytorch_misc import pad_sequence\n",
    "\n",
    "\n",
    "from torch.autograd import Variable as V\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms as trn\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "def _load_resnet(pretrained=True):\n",
    "    # huge thx to https://github.com/ruotianluo/pytorch-faster-rcnn/blob/master/lib/nets/resnet_v1.py\n",
    "    backbone = resnet.resnet50(pretrained=False)\n",
    "    if pretrained:\n",
    "        backbone.load_state_dict(model_zoo.load_url(\n",
    "            'https://s3.us-west-2.amazonaws.com/ai2-rowanz/resnet50-e13db6895d81.th'))\n",
    "    for i in range(2, 4):\n",
    "        getattr(backbone, 'layer%d' % i)[0].conv1.stride = (2, 2)\n",
    "        getattr(backbone, 'layer%d' % i)[0].conv2.stride = (1, 1)\n",
    "    return backbone\n",
    "\n",
    "\n",
    "def _load_resnet_imagenet(pretrained=True):\n",
    "    # huge thx to https://github.com/ruotianluo/pytorch-faster-rcnn/blob/master/lib/nets/resnet_v1.py\n",
    "\n",
    "    \n",
    "    backbone = resnet.resnet50(pretrained=pretrained)\n",
    "    \n",
    "    \n",
    "    for i in range(2, 4):\n",
    "        getattr(backbone, 'layer%d' % i)[0].conv1.stride = (2, 2)\n",
    "        getattr(backbone, 'layer%d' % i)[0].conv2.stride = (1, 1)\n",
    "    # use stride 1 for the last conv4 layer (same as tf-faster-rcnn)\n",
    "    backbone.layer4[0].conv2.stride = (1, 1)\n",
    "    backbone.layer4[0].downsample[0].stride = (1, 1)\n",
    "\n",
    "    # # Make batchnorm more sensible\n",
    "    # for submodule in backbone.modules():\n",
    "    #     if isinstance(submodule, torch.nn.BatchNorm2d):\n",
    "    #         submodule.momentum = 0.01\n",
    "\n",
    "    return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 4):\n",
    "    print()\n",
    "    getattr(backbone, 'layer%d' % i)[0].conv1.stride = (2, 2)\n",
    "    getattr(backbone, 'layer%d' % i)[0].conv2.stride = (1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected a list of 2 ints but got 4 for argument #2 'output_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-7a456c24a69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0morg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0morg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morg_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnew_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/modules/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nn.{} is deprecated. Use nn.functional.interpolate instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners)\u001b[0m\n\u001b[1;32m   2445\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got 4D input, but linear mode needs 3D input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample_bilinear2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_output_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trilinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Got 4D input, but trilinear mode needs 5D input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected a list of 2 ints but got 4 for argument #2 'output_size'"
     ]
    }
   ],
   "source": [
    "images = torch.randn([96, 3, 384, 768])\n",
    "org_size = images.size()\n",
    "m = nn.Upsample(size= [org_size[0],org_size[1],256,256],mode = 'bilinear')\n",
    "new_images = m(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "centre_crop = trn.Compose([\n",
    "            trn.Resize((256,256)),\n",
    "            trn.CenterCrop(224),\n",
    "            trn.ToTensor(),\n",
    "            trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/tensor.py:287: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "requested resize to [96, 3, 256, 256] ([96, 3, 256, 256] elements in total), but the given tensor has a size of 96x3x384x768 (84934656 elements). autograd's resize can only change the shape of a given tensor, while preserving the number of elements. ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cf4fc6075321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"non-inplace resize is deprecated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mResize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mresize_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/autograd/_functions/tensor.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, tensor, sizes)\u001b[0m\n\u001b[1;32m     35\u001b[0m                                 \u001b[0;34m\"tensor, while preserving the number of elements. \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;34m'x'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 'x'.join(map(str, tensor.size())), tensor.numel()))\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_contiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: requested resize to [96, 3, 256, 256] ([96, 3, 256, 256] elements in total), but the given tensor has a size of 96x3x384x768 (84934656 elements). autograd's resize can only change the shape of a given tensor, while preserving the number of elements. "
     ]
    }
   ],
   "source": [
    "size = images.size()\n",
    "images = images.resize([size[0],size[1],256,256])\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = centre_crop(images)\n",
    "input_img = V(temp.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.arange(1, 5).view(1, 1, 2, 2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2.],\n",
       "          [3., 4.]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    " m = nn.Upsample(sizescale_factor=2, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 2., 2.],\n",
       "          [1., 1., 2., 2.],\n",
       "          [3., 3., 4., 4.],\n",
       "          [3., 3., 4., 4.]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3x3 = torch.zeros(3, 3).view(1, 1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2.],\n",
       "          [3., 4.]]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

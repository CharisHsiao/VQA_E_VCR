{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.version' from '/home/lab/anaconda3/envs/nsvqa/lib/python3.6/site-packages/torch/version.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/vcr1images\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/')\n",
    "from dataloaders.vcr import VCR, VCRLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training script. Should be pretty adaptable to whatever.\n",
    "\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.training.learning_rate_schedulers import LearningRateScheduler\n",
    "from allennlp.training.optimizers import Optimizer\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn.modules import BatchNorm2d\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dataloaders.vcr import VCR, VCRLoader\n",
    "from utils.pytorch_misc import time_batch, save_checkpoint, clip_grad_norm, \\\n",
    "    restore_checkpoint, print_para, restore_best_checkpoint\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s', level=logging.DEBUG)\n",
    "\n",
    "# This is needed to make the imports work\n",
    "from allennlp.models import Model\n",
    "import models\n",
    "# import sys\n",
    "# sys.path.append(\"/home/lab/A305/yifan/vqa/vqa-exp/r2c/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-no_tqdm'], dest='no_tqdm', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#################################\n",
    "#################################\n",
    "######## Data loading stuff\n",
    "#################################\n",
    "#################################\n",
    "\n",
    "parser = argparse.ArgumentParser(description='train')\n",
    "parser.add_argument(\n",
    "    '-params',\n",
    "    dest='params',\n",
    "    help='Params location',\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-rationale',\n",
    "    action=\"store_true\",\n",
    "    help='use rationale',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-folder',\n",
    "    dest='folder',\n",
    "    help='folder location',\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\n",
    "    '-no_tqdm',\n",
    "    dest='no_tqdm',\n",
    "    action='store_true',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiAttentionQA_Scene\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args()\n",
    "args.params = \"multiatt_scene/default.json\"\n",
    "args.folder = \"saves/scene_r2c/flagship_answer\"\n",
    "params = Params.from_file(args.params)\n",
    "param=params['model']\n",
    "print(param['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_train.h5\n",
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_val.h5\n",
      "Only relevant dets\n",
      "Loading embeddings from /home/lab/A305/yifan/vqa/vqa-exp/VQA_E_VCR/data/bert_da_answer_test.h5\n"
     ]
    }
   ],
   "source": [
    "train, val, test = VCR.splits(mode='rationale' if args.rationale else 'answer',\n",
    "                              embs_to_load=params['dataset_reader'].get('embs', 'bert_da'),\n",
    "                              only_use_relevant_dets=params['dataset_reader'].get('only_use_relevant_dets', True))\n",
    "NUM_GPUS = torch.cuda.device_count()\n",
    "NUM_CPUS = multiprocessing.cpu_count()\n",
    "if NUM_GPUS == 0:\n",
    "    raise ValueError(\"you need gpus!\")\n",
    "\n",
    "def _to_gpu(td):\n",
    "    if NUM_GPUS > 1:\n",
    "        return td\n",
    "    for k in td:\n",
    "        if k != 'metadata':\n",
    "            td[k] = {k2: v.cuda(non_blocking=True) for k2, v in td[k].items()} if isinstance(td[k], dict) else td[k].cuda(\n",
    "                non_blocking=True)\n",
    "    return td\n",
    "num_workers = (4 * NUM_GPUS if NUM_CPUS >= 32 else 2*NUM_GPUS)-1\n",
    "#print(f\"Using {num_workers} workers out of {NUM_CPUS} possible\", flush=True)\n",
    "# print(f\"Using {num_workers} workers out of {NUM_CPUS} possible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WTF? for answer\n"
     ]
    }
   ],
   "source": [
    "loader_params = {'batch_size': 96 // NUM_GPUS, 'num_gpus':NUM_GPUS, 'num_workers':num_workers}\n",
    "train_loader = VCRLoader.from_dataset(train, **loader_params)\n",
    "val_loader = VCRLoader.from_dataset(val, **loader_params)\n",
    "test_loader = VCRLoader.from_dataset(test, **loader_params)\n",
    "\n",
    "ARGS_RESET_EVERY = 100\n",
    "#print(\"Loading {} for {}\".format(params['model'].get('type', 'WTF?'), 'rationales' if args.rationale else 'answer'), flush=True)\n",
    "print(\"Loading {} for {}\".format(params['model'].get('type', 'WTF?'), 'rationales' if args.rationale else 'answer'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/26/2019 15:00:11 - INFO - allennlp.common.from_params -   instantiating class <class 'allennlp.models.model.Model'> from params {} and extras {'vocab': <allennlp.data.vocabulary.Vocabulary object at 0x7f9793caa5f8>}\n"
     ]
    },
    {
     "ename": "ConfigurationError",
     "evalue": "'key \"type\" is required at location \"model.\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConfigurationError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-76e740a4cfb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/allennlp/common/from_params.py\u001b[0m in \u001b[0;36mfrom_params\u001b[0;34m(cls, params, **extras)\u001b[0m\n\u001b[1;32m    261\u001b[0m             choice = params.pop_choice(\"type\",\n\u001b[1;32m    262\u001b[0m                                        \u001b[0mchoices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_registrable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                                        default_to_first_choice=default_to_first_choice)\n\u001b[0m\u001b[1;32m    264\u001b[0m             \u001b[0msubclass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistered_subclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop_choice\u001b[0;34m(self, key, choices, default_to_first_choice)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[1;32m    254\u001b[0m         \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdefault_to_first_choice\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mkey_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nsvqa/lib/python3.6/site-packages/allennlp/common/params.py\u001b[0m in \u001b[0;36mpop\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"key \\\"{}\\\" is required at location \\\"{}\\\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: 'key \"type\" is required at location \"model.\"'"
     ]
    }
   ],
   "source": [
    "model = Model.from_params(vocab=train.vocab, params=params['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for submodule in model.detector.backbone.modules():\n",
    "    if isinstance(submodule, BatchNorm2d):\n",
    "        submodule.track_running_stats = False\n",
    "    for p in submodule.parameters():\n",
    "        p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
